# Paper-list-for-AI
From Ilya Sutskever Recommended Reading + Other Influential Papers

## üìö Ilya Sutskever's Recommended Reading List

> ‚ÄúIf you deeply understand all of these, you‚Äôll know 90% of what matters today.‚Äù  
> ‚Äî Ilya Sutskever, shared with John Carmack

1. **[Transformer Visualization]** [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)
2. **[Thermodynamics & Complexity]** [The First Law of Complexodynamics](https://scottaaronson.blog/?p=762)
3. **[RNN Intuition]** [The Unreasonable Effectiveness of RNNs](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)
4. **[LSTM Tutorial]** [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
5. **[RNN Regularization]** [Recurrent Neural Network Regularization (Zaremba et al., 2014)](https://arxiv.org/pdf/1409.2329.pdf)
6. **[MDL in Neural Nets]** [Keeping Neural Networks Simple by Minimizing the Description Length of the Weights (Hinton, van Camp, 1993)](https://www.cs.toronto.edu/~hinton/absps/colt93.pdf)
7. **[Pointer Networks]** [Pointer Networks (Vinyals et al., 2015)](https://arxiv.org/pdf/1506.03134.pdf)
8. **[CNN Landmark]** [ImageNet Classification with Deep CNNs (Krizhevsky et al., 2012)](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
9. **[Set-to-Sequence Modeling]** [Order Matters: Sequence to sequence for sets (Vinyals et al., 2015)](https://arxiv.org/pdf/1511.06391.pdf)
10. **[Model Parallelism]** [GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism (Huang et al., 2018)](https://arxiv.org/pdf/1811.06965.pdf)
11. **[Residual Networks]** [Deep Residual Learning for Image Recognition (He et al., 2015)](https://arxiv.org/pdf/1512.03385.pdf)
12. **[Dilated Convolutions]** [Multi-Scale Context Aggregation by Dilated Convolutions (Yu & Koltun, 2015)](https://arxiv.org/pdf/1511.07122.pdf)
13. **[Message Passing for Molecules]** [Neural Message Passing for Quantum Chemistry (Gilmer et al., 2017)](https://arxiv.org/pdf/1704.01212.pdf)
14. **[Transformer Architecture]** [Attention Is All You Need (Vaswani et al., 2017)](https://arxiv.org/pdf/1706.03762.pdf)
15. **[Neural Alignment]** [Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau et al., 2014)](https://arxiv.org/pdf/1409.0473.pdf)
16. **[ResNet Optimization]** [Identity Mappings in Deep Residual Networks (He et al., 2016)](https://arxiv.org/pdf/1603.05027.pdf)
17. **[Relational Reasoning]** [A Simple Neural Network Module for Relational Reasoning (Santoro et al., 2017)](https://arxiv.org/pdf/1706.01427.pdf)
18. **[Variational Autoencoder]** [Variational Lossy Autoencoder (Chen et al., 2016)](https://arxiv.org/pdf/1611.02731.pdf)
19. **[Relational RNN]** [Relational Recurrent Neural Networks (Santoro et al., 2018)](https://arxiv.org/pdf/1806.01822.pdf)
20. **[Cellular Automata Complexity]** [Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton (Aaronson et al., 2014)](https://arxiv.org/pdf/1405.6903.pdf)
21. **[Memory-Augmented Models]** [Neural Turing Machines (Graves et al., 2014)](https://arxiv.org/pdf/1410.5401.pdf)
22. **[End-to-End Speech Recognition]** [Deep Speech 2: End-to-End Speech Recognition (Amodei et al., 2015)](https://arxiv.org/pdf/1512.02595.pdf)
23. **[Scaling Laws]** [Scaling Laws for Neural Language Models (Kaplan et al., 2020)](https://arxiv.org/pdf/2001.08361.pdf)
24. **[Information Theory]** [A Tutorial Introduction to the Minimum Description Length Principle (Gr√ºnwald, 2004)](https://arxiv.org/pdf/math/0406077.pdf)
25. **[Superintelligence Foundations]** [Machine Super Intelligence Dissertation (Shane Legg, 2008)](https://www.vetta.org/documents/Machine_Super_Intelligence.pdf)
26. **[Kolmogorov Complexity]** [Kolmogorov Complexity: Page 434 onward (Shen, Uspensky, Vereshchagin)](https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf)
27. **[CNN Course]** [CS231n: CNNs for Visual Recognition (Stanford)](https://cs231n.github.io/)


---

## üîó Credits

- Based on public share by Ilya Sutskever to John Carmack.
- Curated by the community with ‚ù§Ô∏è.


## üìö Other Influential Papers (via LifeArchitect.ai)
ÂèÇËÄÉÁîüÂëΩÊû∂ÊûÑÂπ≥Âè∞ LifeArchitect.ai Êé®ËçêÁöÑÂ§ñÈÉ®ÈáçË¶ÅËÆ∫ÊñáÔºåË°•ÂÖÖ Ilya ÂéüÂßãÂàóË°®‰πãÂ§ñÁöÑÈáçË¶ÅËµÑÊ∫êÔºö

- **[GPT‚Äë4 Technical Report](Other-Influential-Papers/GPT-4_Technical_Report/README.md)** ‚Äï OpenAI 2023 (PDF)
- **[GPT‚Äë4 System Card](Other-Influential-Papers/GPT-4_System_Card/README.md)** ‚Äï OpenAI 2023 (PDF)
- **[PaLM¬†2 Technical Report](Other-Influential-Papers/PaLM2_Technical_Report/README.md)** ‚Äï Google 2023 (PDF)
- **[Sparks of AGI: early GPT‚Äë4 experiments](Other-Influential-Papers/Sparks_AGI_GPT4/README.md)** ‚Äï Bubeck et al. 2023
- **[GPT‚Äë4.5 ‚ÄúOrion‚Äù Overview](Other-Influential-Papers/GPT-4.5_Orion/README.md)** ‚Äï OpenAI Feb 2025
- **[GPT‚Äë4.1 Overview](Other-Influential-Papers/GPT-4.1/README.md)** ‚Äï OpenAI Apr 2025
